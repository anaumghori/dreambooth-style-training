# dreambooth-style-training
This repository features an implementation of DreamBooth with Stable Diffusion for training custom styles
# 💻 Setup and the Dataset
I ran everything on Google Colab, which is awesome because they give you free access to a Tesla T4 GPU and about 15GB of RAM. This setup is great for average or basic training where you just want to learn and get comfortable with DreamBooth. However, for high-level training with larger datasets or more complex projects, you might run into out-of-memory errors—this is pretty common on Colab. In such cases, you may need to look for better hardware or a more robust system. For reference, my training utilized about 11.4GB of RAM out of the 15GB available. 

The dataset I used consisted of 24 high-quality manhwa images, and trust me, the quality of your images makes all the difference — bad inputs lead to bad outputs. To get the best results, avoid using blurry or low-resolution images and make sure to remove watermarks, text, or graininess, as these can mess up the model’s training. Cropping all images to the same size might also help, but honestly, I skipped that step and still managed to get decent results! Nearly 97% of the images I used focused on faces. If you’re training to copy a specific style, make sure the style is consistent across all images. Mixing styles or having varied lighting on the subject increases the chances of incorrect outputs. 

I stored all my images randomly in a single google drive folder without labeling them or organizing them into class-specific subfolders. If you’d like, you can organize your dataset into folders based on classes, like “men” or “women,” within a root folder. However, since I didn’t try this approach, I can’t say for sure if it improves training or how it affects the overall results.
